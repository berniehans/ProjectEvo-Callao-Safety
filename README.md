# ğŸ§¬ ProjectEvo: OptimizaciÃ³n Neuro-Evolutiva para Seguridad Ciudadana

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)
![PyGAD](https://img.shields.io/badge/AI-Evolutionary-green)
![Status](https://img.shields.io/badge/Status-Finalizado-success)

> **Tesis de MaestrÃ­a:** ImplementaciÃ³n de un sistema hÃ­brido (Deep Learning + Algoritmos GenÃ©ticos) para la clasificaciÃ³n de incidentes crÃ­ticos en escenarios de alto desbalance de datos (Callao, PerÃº).

---

## ğŸ“‹ DescripciÃ³n del Proyecto

Este repositorio contiene el cÃ³digo fuente y los experimentos desarrollados para el curso **ComputaciÃ³n Evolutiva (MAE-IA 2025-II)** de la **Universidad Nacional de IngenierÃ­a (UNI)**.

El objetivo principal es resolver el problema de clasificaciÃ³n de textos cortos (reportes de seguridad) donde existe un desbalance extremo: miles de reportes rutinarios ("Ambientales") frente a escasos eventos crÃ­ticos ("ProtecciÃ³n Familiar", "FÃ­sica").

**SoluciÃ³n Propuesta:** Un pipeline que integra **BERT** para la extracciÃ³n de caracterÃ­sticas semÃ¡nticas y **Algoritmos GenÃ©ticos (GA)** para optimizar tanto la selecciÃ³n de caracterÃ­sticas como los hiperparÃ¡metros de entrenamiento (especialmente los pesos de la funciÃ³n de pÃ©rdida), culminando en un **Ensemble Evolutivo**.

---

## ğŸš€ Pipeline de IngenierÃ­a (MetodologÃ­a)

El proyecto se divide en 5 notebooks secuenciales que representan las fases de investigaciÃ³n:

### ğŸ”¹ Fase 1: LÃ­nea Base y RepresentaciÃ³n (`01_Baseline` & `02_BERT`)
* TransformaciÃ³n de textos crudos a vectores densos usando **BERT Multilingual**.
* GeneraciÃ³n de embeddings de 768 dimensiones que capturan el contexto semÃ¡ntico.
* *Resultado:* Dataset procesado y fragmentado para manejo eficiente de memoria.

### ğŸ”¹ Fase 2: SelecciÃ³n Evolutiva de CaracterÃ­sticas (`03_GA_FeatureSelection`)
* Uso de un Algoritmo GenÃ©tico para reducir la dimensionalidad.
* **Logro:** Se redujo el espacio de entrada de 768 a **92 caracterÃ­sticas clave** (reducciÃ³n del 88%), eliminando ruido y mejorando la velocidad de entrenamiento sin sacrificar precisiÃ³n.

### ğŸ”¹ Fase 3: ValidaciÃ³n de Arquitectura (`04_NAS_NeuroEvolution`)
* ComparaciÃ³n empÃ­rica ("Architecture Showdown") de topologÃ­as neuronales.
* **DecisiÃ³n:** SelecciÃ³n de una arquitectura **3 capas ocultas x 512 neuronas** basada en el Principio de Parsimonia, superando a modelos mÃ¡s superficiales y masivos.

### ğŸ”¹ Fase 4: OptimizaciÃ³n de HiperparÃ¡metros (`05_Evolutionary_Ensemble`)
* Ajuste fino evolutivo de la "quÃ­mica" del entrenamiento: *Learning Rate*, *Dropout* y *Alpha* (Weighted Loss).
* **InnovaciÃ³n:** El GA descubriÃ³ que penalizar **5 veces mÃ¡s (Alpha=5.0)** los errores en clases crÃ­ticas era la clave para romper la barrera del desbalance.

### ğŸ”¹ Fase 5: ProducciÃ³n (`05_Evolutionary_Ensemble`)
* Despliegue de un **ComitÃ© de Expertos (Ensemble)** de 5 modelos entrenados con semillas distintas (Bagging).
* Inferencia final mediante votaciÃ³n ponderada.

---

## ğŸ“‚ Estructura del Repositorio

```text
ProjectEvo-Callao-Safety/
â”‚
â”œâ”€â”€ data/                   # Datos crudos (no incluidos por privacidad)
â”œâ”€â”€ data_processed/         # Embeddings de BERT fragmentados (.pt)
â”œâ”€â”€ models/                 # Artefactos entrenados
â”‚   â”œâ”€â”€ ga_feature_mask.pt  # MÃ¡scara binaria (92 features)
â”‚   â””â”€â”€ production_final.pt # Pesos del Ensemble final
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_Baseline_Clasico.ipynb       # Modelos tradicionales (SVM, RF)
â”‚   â”œâ”€â”€ 02_BERT_Embeddings.ipynb        # ExtracciÃ³n de features con Transformers
â”‚   â”œâ”€â”€ 03_GA_FeatureSelection.ipynb    # ReducciÃ³n de dimensionalidad con PyGAD
â”‚   â”œâ”€â”€ 04_NAS_NeuroEvolution.ipynb     # BÃºsqueda de arquitectura y validaciÃ³n
â”‚   â””â”€â”€ 05_Evolutionary_Ensemble.ipynb  # Tuning, Ensemble y EvaluaciÃ³n Final
â”‚
â”œâ”€â”€ requirements.txt        # Dependencias del proyecto
â””â”€â”€ README.md               # Este archivo